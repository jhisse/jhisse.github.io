---
title: Os V's do Big Data
date: 2019-10-06
layout: default
---

No ano de 2001 Doug Laney propôs os primeiros 3 V's em seu artigo "3D Data Management: Controlling Data Volume, Velocity, and Variety". O autor define o primeiro V como Volume. O volume se caracteriza pela grande quantidade de dados, lembrando que o que é considerado de grande volume hoje, por exemplo, petabytes, pode ser normal daqui a uns anos, e o que foi gigantesco no passado, por exemplo, terabytes, hoje é considerado algo mais comum.


O segundo V se refere a velocidade de acesso aos dados. A tomada de decisão em determinados cenários pode ser influenciada diretamente por esta característica. Imagine um e-commerce de grande porte ficando cerca de 5 minutos fora do ar ou até uma rede social ficando alguns minutos sem respostas do servidor.


Já o terceiro V fica por conta da variedade. A variedade trata dos diferentes formatos, semântica e estruturas. Neste ponto é fundamental unificar seus dados em uma estrutura padrão e com significado, afim de garantir a interoperabilidade, ou seja, como os dados interagem entre si.


Em 2012 surgiram dois novos V's, veracidade e valor, o primeiro se refere a confiança e limpeza do dado e o segundo ao valor agregado do dado, ou seja, se o dado obtido responde a um questinamento do negócio.


Em abril de 2017, Tom Shafer, cientista de dados, publicou o artigo "The 42 V's of Big Data and Data Science", onde descreveu de forma cômica os 42 V's que caracterizariam Big Data. Claro que o artigo foi uma crítica a forma como as empresas estavam tornando o tema algo comercial.


## Fontes

- <https://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf>
- <https://www.elderresearch.com/blog/42-v-of-big-data>
